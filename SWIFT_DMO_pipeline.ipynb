{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ec597a",
   "metadata": {},
   "source": [
    "# SWIFTCON 2025 - The \"fiducial\" simulation pipeline\n",
    "\n",
    "This notebook takes you through an example of running a dark-matter-only simulation and creating subhalo catalogues for subsequent analysis. The software used throughout this tutorial is the following:\n",
    "\n",
    "* **Initial conditions**: monofonIC. [Code repository](https://bitbucket.org/ohahn/monofonic/src/master/) and latest [reference paper](https://ui.adsabs.harvard.edu/abs/2020ascl.soft08024H/abstract).\n",
    "* **Cosmological integration**: SWIFT. [Code repository](https://gitlab.cosma.dur.ac.uk/swift/swiftsim) and [reference paper](https://ui.adsabs.harvard.edu/abs/2024MNRAS.530.2378S/abstract).\n",
    "* **Subhalo finding**: HBT-HERONS. [Code repository](https://github.com/SWIFTSIM/HBT-HERONS) and [reference paper](https://ui.adsabs.harvard.edu/abs/2025MNRAS.543.1339F/abstract).\n",
    "* **Subhalo property calculation**: SOAP. [Code repository](https://github.com/SWIFTSIM/SOAP) and [reference paper](https://ui.adsabs.harvard.edu/abs/2025JOSS...10.8252M/abstract).\n",
    "\n",
    "Created by Victor Forouhar Moreno (forouhar@strw.leidenuniv.nl) & Rob McGibbon (mcgibbon@strw.leidenuniv.nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f22971d-618a-4b6e-b835-0c1825f25dbb",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Several external libraries are required to compile and/or run the codes used in this tutorial, although there is considerable overlap across codes. If you are using the provided Docker image, all libraries are pre-installed and ready to go. If you are not using the provided image, you will need to install these libraries yourself.\n",
    "\n",
    "#### monofonIC\n",
    "- FFTW\n",
    "- GSL\n",
    "- HDF5\n",
    "\n",
    "#### SWIFT\n",
    "- HDF5 \n",
    "- MPI\n",
    "- FFTW\n",
    "- METIS\n",
    "- GSL\n",
    "\n",
    "#### HBT-HERONS\n",
    "- CMake\n",
    "- HDF5\n",
    "- MPI\n",
    "\n",
    "#### SOAP\n",
    "- mpi4py\n",
    "- h5py built with parallel HDF5\n",
    "- Standard python modules (see requirements.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e352a2-ea6a-4c14-8629-3775a0c7478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p ./outputs/monofonic ./outputs/SWIFT  ./outputs/HBT-HERONS ./outputs/SOAP ./software "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3a9a6",
   "metadata": {},
   "source": [
    "# Generating initial conditions\n",
    "\n",
    "#### Clone repository\n",
    "\n",
    "We need to download monofonIC first, for which we clone the official repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f361e6-9cc9-402b-9713-1b27ba1f6ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://bitbucket.org/ohahn/monofonic.git ./software/monofonic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95051db-a051-4cdf-8108-6e13c582808a",
   "metadata": {},
   "source": [
    "\n",
    "#### Compiling\n",
    "We then compile the code to generate the executable we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a17292-10b0-4ea7-8661-1f5696bf520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ./software/monofonic/\n",
    "mkdir build/ && cd build\n",
    "\n",
    "# Compilation options can be optionally specified at this stage.\n",
    "cmake ..\n",
    "make -j 4\n",
    "\n",
    "# Go back to original directory\n",
    "cd ../../.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aee3016-7489-4421-8294-cebf664abe46",
   "metadata": {},
   "source": [
    "#### Running monofonIC\n",
    "\n",
    "The monofonIC executable takes the path to a parameter file as a runtime argument. In this parameter file, you can specify the redshift at which the ICs will be generated, the cosmological parameters and , among other things. \n",
    "\n",
    "We have provided a basic parameter file in `./parameter_files/monofonic/example.conf`. Note that the following mandatory parameters have been left unspecified, as we encourage you to play with their value:\n",
    "\n",
    "* `GridRes`: number of particles per dimension. Total number of particles will be the cube of this number.\n",
    "* `BoxLength`: Length of each side of the cubic box. **It should be in `Mpc/h`!** \n",
    "\n",
    "TIP: if you want a lot of structure that forms at high redshift at a fixed value of `GridRes`, you can can make a \"smarter\" box size choice by recalling the shape of the LCDM power spectrum and/or mass function :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb81b24-5661-4928-8027-3790ab52b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "~/tutorial/software/monofonic/build/monofonIC ./parameter_files/monofonic/example.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4452982",
   "metadata": {},
   "source": [
    "# Running simulation\n",
    "\n",
    "[SWIFT](https://swift.strw.leidenuniv.nl/docs/index.html) is an open-source cosmological and astrophysical numerical solver designed to run efficiently on modern hardware. A comprehensive and extensive set of models for galaxy formation as well as planetary physics are provided alongside a large series of examples.\n",
    "\n",
    "#### Clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://gitlab.cosma.dur.ac.uk/swift/swiftsim.git ~/tutorial/software/swiftsim/\n",
    "cd ~/tutorial/software/swiftsim/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a24db2",
   "metadata": {},
   "source": [
    "#### Compiling\n",
    "\n",
    "Compiling SWIFT is a bit more involved than monofonIC, see the [notes here](https://swift.strw.leidenuniv.nl/docs/GettingStarted/compiling_code.html).\n",
    "\n",
    "Luckily for our purposes, which is to run a dark-matter-only simulation to be analysed with HBT-HERONS, we only need to pass the `--enable-fof` flag. This will make the Friends-of-Friends group algorithm available within SWIFT, which is required by HBT-HERONS to find subhaloes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e49ac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "./autogen.sh\n",
    "./configure --enable-fof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6592255-565b-4d0a-98b3-4c855db9ee53",
   "metadata": {},
   "source": [
    "Then compile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0234421-d2f6-430b-a944-46cb1f859a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make -j 4\n",
    "cd ~/tutorial/outputs/SWIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8251d1",
   "metadata": {},
   "source": [
    "#### Running SWIFT\n",
    "\n",
    "We will run the non-MPI version of the code (MPI version is `swift_mpi`). Aside from the path to a parameter file, we need to specify that this simulation is cosmological (`--cosmology`), particles have gravity (`--self-gravity`) and that we want to run the Friends-of-Friends algorithm (`--fof`).\n",
    "\n",
    "In the parameter file, you will need to specify the cosmology you chose during IC generation, as well as the gravity softening length (set it to 1/25th of the mean interparticle separation, i.e. `BoxLength / GridRes / 25`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b079ca8-6d47-41e2-b3e5-c00c6c679a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir outputs/SWIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "~/tutorial/software/swiftsim/swift --cosmology --self-gravity --fof --threads=16 ~/tutorial/parameter_files/SWIFT/configuration.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e50eb",
   "metadata": {},
   "source": [
    "#### Output of run\n",
    "\n",
    "- `snap_xxxx.hdf5` - Particles and their properties\n",
    "- `fof_output_xxxx.hdf5` - FOF halo catalogue (FOF IDs stored in snapshots)\n",
    "- `statistics.txt` - Global properties of the simulation over time\n",
    "- `timesteps.txt` - What the simulation did during it's timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc4c24",
   "metadata": {},
   "source": [
    "# Subhalo finding\n",
    "\n",
    "HBT-HERONS uses the FOF catalogues from SWIFT to as candidates for central subhalos. Once a subhalo has been identified at any snapshot, the particles remain associated to it even if it falls into a larger halo. Using this information makes it possible to identify satellite subhalos.\n",
    "\n",
    "Given the history-based method of HBT-HERONS, it needs to analyse a range of snapshots from the simulation. We recommend at least ~64 snapshot spaced evenly in $\\log a$.\n",
    "\n",
    "Hydro considerations\n",
    "- SWIFT particle splitting\n",
    "- Which particles to use as tracers\n",
    "- Number of tracers for an object to be resolved\n",
    "- Thermal energy of gas particles\n",
    "\n",
    "#### Clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bfc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/SWIFTSIM/HBT-HERONS ~/tutorial/software/HBT-HERONS/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac609b",
   "metadata": {},
   "source": [
    "#### Compiling\n",
    "\n",
    "Several compile-time options can be set using CMAKE, which include the size of internal datatypes (for memory consideration), whether the simulation is hydrodynamical or not, and whether to include the gas internal energy during unbinding. The full list of options can be seen using `ccmake`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b5c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/tutorial/software/HBT-HERONS/\n",
    "mkdir build && cd build\n",
    "\n",
    "cmake ../ -D HBT_USE_OPENMP=ON -D HBT_DM_ONLY=ON -D HBT_UNSIGNED_LONG_ID_OUTPUT=OFF\n",
    "make -j 4\n",
    "\n",
    "cd ~/tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a3f033",
   "metadata": {},
   "source": [
    "#### Running HBT-HERONS\n",
    "\n",
    "The HBT-HERONS executable takes the path to a parameter file as a runtime argument. In this parameter file, you specify several parameters that relate to tracking subhaloes, how unbinding is done and the path to the simulation to analyse. \n",
    "\n",
    "We have provided a basic parameter file in `./parameter_files/HBT-HERONS/SWIFT.conf`. Note that you will need to add a value to `MaxSnapshotIndex` that corresponds to the total number of snapshots that the simulation you want to analyse has.\n",
    "\n",
    "You can run HBT-HERONS over MPI and with multiple threads per rank. The number of MPI ranks determines the (spatially-based) domain decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1acae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "export OMP_NUM_THREADS=8\n",
    "mpirun --allow-run-as-root -np 1 ~/tutorial/software/HBT-HERONS/build/HBT ~/tutorial/parameter_files/HBT-HERONS/SWIFT.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f301e1",
   "metadata": {},
   "source": [
    "#### Output of run\n",
    "\n",
    "For each snapshot each HBT rank outputs two files.\n",
    "- The `SubSnap_xxx.y.hdf5` files contain information about the bound subhalos identified by HBT-HERONS, including their particles. There are only a very small number of halo properties contained in these files. All information for merger trees is also contained within these files.\n",
    "- The `SrcSnap_xxx.y.hdf5` files contain a list of the particles associated with each subhalo, which can also include unbound at the current snapshot. These files are only used if HBT-HERONS if restarted, and so can be deleted once halo finding has been completed.\n",
    "\n",
    "HBT-HERONS contains \"orphan\" subhalos. These are subhalos which have been disrupted, but are still tracked by the most bound particle at the time the last snapshot the subhalo was resolved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393cc36",
   "metadata": {},
   "source": [
    "# SOAP - Calculating halo properties\n",
    "\n",
    "SOAP is a python package that loads in SWIFT simulation data, a subhalo catalogue containing particle bound memberships and subhalo centres, and can compute **many** properties. \n",
    "\n",
    "There are several different types of available aperture properties, which depend on whether a spherical cut is used to select particles or not, as well as whether the boundness of particles is accounted for. It can also automatically calculate the physical size of apertures that reach a given spherical overdensity, and disable the calculation of properties if the number of particles is insufficient to get reasonable results.\n",
    "\n",
    "There are two steps involved in running SOAP:\n",
    "\n",
    "* **Generating particle memberships**: SOAP loads the particle bound memberships from the subhalo catalogue and reorders them in the same order as the SWIFT simulation snapshot. This will be used later to apply boundness selections to particles during the subhalo property calculation step. You can also use these memberships to generate a virtual snapshot, to facilitate the selection of particles bound to a subhalo of interest.\n",
    "* **Calculating subhalo properties**: SOAP loads the bound memberships of particles and the snapshot data, computes the requested properties, and saves an HDF5 file that is unit-aware.\n",
    "\n",
    "#### Clone and install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e39466",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/SWIFTSIM/SOAP.git ~/tutorial/software/SOAP\n",
    "cd ~/tutorial/software/SOAP\n",
    "pip install -e .\n",
    "cd ~/tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4964637-dc6f-43fc-8f97-0844e1e53c73",
   "metadata": {},
   "source": [
    "#### Running the group membership files\n",
    "\n",
    "Should be relatively cheap, just reads in the particles for each halo, resorts them, and outputs them in a SWIFT friendly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpirun --allow-run-as-root -np 4 python3 -u ~/tutorial/software/SOAP/SOAP/group_membership.py \\\n",
    "    --sim-name=DM_test \\\n",
    "    --snap-nr=49      \\\n",
    "    ~/tutorial/parameter_files/SOAP/DMO_EXAMPLE.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f87c78-d5a2-4109-8544-008ed05a36e0",
   "metadata": {},
   "source": [
    "#### Calculating halo properties\n",
    "\n",
    "Chunks sets how to split up the simulation volume. We require multiple chunks if running on multiple nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d25f1-f71c-417f-9ef0-e361ca2d474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpirun --allow-run-as-root -np 4 python3 -u ~/tutorial/software/SOAP/SOAP/compute_halo_properties.py \\\n",
    "    --sim-name=DM_test \\\n",
    "    --snap-nr=49 \\\n",
    "    --chunks=1 \\\n",
    "    --dmo \\\n",
    "    ~/tutorial/parameter_files/SOAP/DMO_EXAMPLE.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac031ea-7a37-463f-afc2-57987b3b595e",
   "metadata": {},
   "source": [
    "#### SOAP output\n",
    "\n",
    "Membership files have the same structure as a SWIFT snapshot. There are no particle IDs, but the particles are in the same order as the original snapshot.\n",
    "\n",
    "SOAP catalogues have a group for each halo type. All arrays have the same length (the number of subhalos), and are always in the same order.\n",
    "\n",
    "See tomorrow's tutorial on more information on how to use SWIFT, SOAP and merger tree data to analyse the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74915592-18f0-4183-af1a-2d599a837db6",
   "metadata": {},
   "source": [
    "#### Compression, virtual snapshots, documentation (not working in docker)\n",
    "\n",
    "The files output from SOAP can be heavily compressed. For the membership files this is because most particles are not in a halo, and there are many repeated indices for the ones that are. For the halo properties we do not compute certain properties depending on the size of the input halo, so many values are zero.\n",
    "\n",
    "The membership files have no lossy compression filters, and can be compressed with h5repack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7054c-431f-46a4-b0ed-4ae4acdb419f",
   "metadata": {},
   "source": [
    "We can create a single virtual file which links the memebership files with the snapshot files so that the datasets in both can be accessed at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128788fd-1d12-4133-acc8-323b95ad4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5repack -i outputs/SOAP/SOAP_uncompressed/membership_0049.hdf5 -o outputs/SOAP/membership_0049.hdf5 -f GZIP=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffa38c-aa91-4ea5-9928-5a8dd134d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 software/SOAP/compression/make_virtual_snapshot.py \\\n",
    "    outputs/SWIFT/snap_0049.hdf5 \\\n",
    "    outputs/SOAP/membership_0049/membership_0049.hdf5 \\\n",
    "    outputs/SOAP/snapshot_with_membership_0049.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73d9f1a-a28b-47ff-a6e4-4966d5c08a0e",
   "metadata": {},
   "source": [
    "The halo catalogues have the same lossy compression filters as are available in SWIFT (some of which are custom), and so must be compressed using the following script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ad4f6-1a42-4ef7-8739-eec259f53c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 software/SOAP/SOAP/compression/compress_soap_catalogue.py \\\n",
    "    SOAP_uncompressed/halo_properties_0049.hdf5 \\\n",
    "    halo_properties_0049.hdf5 \\\n",
    "    outputs/SOAP/SOAP_uncompressed/tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c39a407-b471-462d-b77d-6d61f7d6217c",
   "metadata": {},
   "source": [
    "#### Generate documentation\n",
    "\n",
    "Documentation can be generated by running the `property_table.py`. You must pass the parameter file (to determine which halo types and properties are included in the documentation) and a SWIFT snapshot (to extract the units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d5583-a4f2-486c-a382-644113be9898",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd software/SOAP\n",
    "python3 SOAP/property_table.py parameter_files/SOAP_config.yml ../../outputs/SWIFT/snap_0018.hdf5\n",
    "cd documentation\n",
    "# pdflatex SOAP.tex\n",
    "cd ../../.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
